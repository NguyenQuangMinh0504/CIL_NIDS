2023-10-18 16:27:37,629 [trainer.py] => Time Str >>> 1018-16-27-37-629
2023-10-18 16:27:37,630 [trainer.py] => memory_per_class: 20
2023-10-18 16:27:37,630 [trainer.py] => fixed_memory: False
2023-10-18 16:27:37,630 [trainer.py] => shuffle: True
2023-10-18 16:27:37,630 [trainer.py] => model_name: memo
2023-10-18 16:27:37,630 [trainer.py] => seed: 1993
2023-10-18 16:27:37,630 [trainer.py] => dataset: cifar100
2023-10-18 16:27:37,630 [trainer.py] => init_cls: 5
2023-10-18 16:27:37,630 [trainer.py] => increment: 5
2023-10-18 16:27:37,630 [trainer.py] => convnet_type: memo_resnet32
2023-10-18 16:27:37,630 [trainer.py] => prefix: benchmark
2023-10-18 16:27:37,630 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)]
2023-10-18 16:27:37,630 [trainer.py] => debug: False
2023-10-18 16:27:37,630 [trainer.py] => train_base: False
2023-10-18 16:27:37,630 [trainer.py] => train_adaptive: False
2023-10-18 16:27:37,630 [trainer.py] => config: ./exps/memo.json
2023-10-18 16:27:37,630 [trainer.py] => time_str: 1018-16-27-37-629
2023-10-18 16:27:37,630 [trainer.py] => exp_name: 1018-16-27-37-629_cifar100_memo_resnet32_1993_B0_Inc5
2023-10-18 16:27:37,630 [trainer.py] => logfilename: logs/benchmark/cifar100/memo/1018-16-27-37-629_cifar100_memo_resnet32_1993_B0_Inc5
2023-10-18 16:27:37,630 [trainer.py] => csv_name: cifar100_1993_memo_resnet32_B0_Inc5
2023-10-18 16:27:40,237 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,249 [memo.py] => >>> train generalized blocks:False train_adaptive: False
2023-10-18 16:27:40,249 [trainer.py] => Start time:1697621260.24932
2023-10-18 16:27:40,249 [trainer.py] => All params: 464
2023-10-18 16:27:40,249 [trainer.py] => Trainable params: 464
2023-10-18 16:27:40,249 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,257 [inc_net.py] => SpecializedResNet_cifar(
  (final_stage): Sequential(
    (0): ResnetBasicblock(
      (conv_a): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResnetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResnetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ResnetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): ResnetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
)
2023-10-18 16:27:40,258 [trainer.py] => All params: 333520
2023-10-18 16:27:40,258 [trainer.py] => Trainable params: 333520
2023-10-18 16:27:40,258 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,270 [trainer.py] => All params: 666576
2023-10-18 16:27:40,271 [trainer.py] => Trainable params: 666576
2023-10-18 16:27:40,271 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,281 [trainer.py] => All params: 999632
2023-10-18 16:27:40,281 [trainer.py] => Trainable params: 999632
2023-10-18 16:27:40,281 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,291 [trainer.py] => All params: 1332688
2023-10-18 16:27:40,291 [trainer.py] => Trainable params: 1332688
2023-10-18 16:27:40,291 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,302 [trainer.py] => All params: 1665744
2023-10-18 16:27:40,302 [trainer.py] => Trainable params: 1665744
2023-10-18 16:27:40,302 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,312 [trainer.py] => All params: 1998800
2023-10-18 16:27:40,313 [trainer.py] => Trainable params: 1998800
2023-10-18 16:27:40,313 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,323 [trainer.py] => All params: 2331856
2023-10-18 16:27:40,323 [trainer.py] => Trainable params: 2331856
2023-10-18 16:27:40,323 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,335 [trainer.py] => All params: 2664912
2023-10-18 16:27:40,335 [trainer.py] => Trainable params: 2664912
2023-10-18 16:27:40,335 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,345 [trainer.py] => All params: 2997968
2023-10-18 16:27:40,346 [trainer.py] => Trainable params: 2997968
2023-10-18 16:27:40,346 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,356 [trainer.py] => All params: 3331024
2023-10-18 16:27:40,357 [trainer.py] => Trainable params: 3331024
2023-10-18 16:27:40,357 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,368 [trainer.py] => All params: 3664080
2023-10-18 16:27:40,369 [trainer.py] => Trainable params: 3664080
2023-10-18 16:27:40,369 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,379 [trainer.py] => All params: 3997136
2023-10-18 16:27:40,380 [trainer.py] => Trainable params: 3997136
2023-10-18 16:27:40,380 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,391 [trainer.py] => All params: 4330192
2023-10-18 16:27:40,392 [trainer.py] => Trainable params: 4330192
2023-10-18 16:27:40,392 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,402 [trainer.py] => All params: 4663248
2023-10-18 16:27:40,403 [trainer.py] => Trainable params: 4663248
2023-10-18 16:27:40,403 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,414 [trainer.py] => All params: 4996304
2023-10-18 16:27:40,415 [trainer.py] => Trainable params: 4996304
2023-10-18 16:27:40,415 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,425 [trainer.py] => All params: 5329360
2023-10-18 16:27:40,426 [trainer.py] => Trainable params: 5329360
2023-10-18 16:27:40,426 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,437 [trainer.py] => All params: 5662416
2023-10-18 16:27:40,438 [trainer.py] => Trainable params: 5662416
2023-10-18 16:27:40,438 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,450 [trainer.py] => All params: 5995472
2023-10-18 16:27:40,451 [trainer.py] => Trainable params: 5995472
2023-10-18 16:27:40,451 [memo_cifar_resnet.py] => Layer block is: 5
2023-10-18 16:27:40,462 [trainer.py] => All params: 6328528
2023-10-18 16:27:40,463 [trainer.py] => Trainable params: 6328528
2023-10-18 16:27:40,463 [memo_cifar_resnet.py] => Layer block is: 5
